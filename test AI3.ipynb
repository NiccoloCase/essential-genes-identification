{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero ottimale di feature: 6\n",
      "Final accuracy with 6 features: 0.8028764805414551\n",
      "Mean bootstrap accuracy: 0.8015693739424704\n",
      "95% confidence interval for accuracy: [0.78600888 0.81790398]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Carica i dati\n",
    "data = pd.read_excel('cerevisiae_data.xls')\n",
    "\n",
    "# Separazione delle feature e della classe target\n",
    "X = data.drop(columns=['Essential', 'orf_id'])\n",
    "y = data['Essential']\n",
    "\n",
    "# Ranking CMIM fornito\n",
    "CMIM_ranking = ['phyletic_retention', 'paralagous_count', 'DIP_degree', 'nucleolus', 'nucleus',\n",
    "                'upstream_size', 'spindle pole', 'GLU', 'Codon_bias', 'aromaticity_score', 'Gravy_score',\n",
    "                'CAI', 'downstream_size', 'vacuole', 'endosome', 'mitochondrion', 'PI', 'cytoplasm',\n",
    "                'promoter_count(Harbison_et_al)', 'vacuolar membrane', 'MET', 'ASP', 'ER to Golgi', 'GLN',\n",
    "                'peroxisome', 'num places loc', 'LYS', 'ambiguous', 'cell periphery', 'FOP_score', \n",
    "                'nuclear periphery', 'ARG', 'Golgi to ER', 'punctate composite', 'ER', 'lipid particle',\n",
    "                'microtubule', 'Golgi', 'bud neck', 'actin', 'bud', 'Golgi to Vacuole']\n",
    "\n",
    "# Ordina le colonne di X secondo il ranking CMIM fornito\n",
    "X_ranked = X[CMIM_ranking]\n",
    "\n",
    "\n",
    "# Discretizzazione delle feature con il metodo Fayyad & Irani (simulato con KBinsDiscretizer)\n",
    "# KBinsDiscretizer applica discretizzazione basata sulla frequenza (approssimazione di Fayyad & Irani)\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "\n",
    "# Lista per salvare i risultati delle PPV\n",
    "ppv_scores = []\n",
    "\n",
    "# Partiamo con tutte le feature e le rimuoviamo una alla volta\n",
    "for i in range(len(CMIM_ranking), 0, -1):\n",
    "    # Seleziona le prime 'i' feature del ranking CMIM\n",
    "    X_selected = X_ranked.iloc[:, :i]\n",
    "    \n",
    "    # Discretizza le feature selezionate\n",
    "    X_discretized = discretizer.fit_transform(X_selected)\n",
    "    \n",
    "    # Dividi i dati in training e test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_discretized, y, test_size=0.5, stratify=y)\n",
    "    \n",
    "    # Crea e addestra il classificatore Naive Bayes\n",
    "    nb_classifier = GaussianNB()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Fai le predizioni sul test set\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    # Calcola la PPV (precision score) per le predizioni positive\n",
    "    ppv_top_5 = precision_score(y_test, y_pred, average='binary')\n",
    "    \n",
    "    # Salva il risultato (numero di feature e PPV)\n",
    "    ppv_scores.append((i, ppv_top_5))\n",
    "\n",
    "# Identifica il numero ottimale di feature\n",
    "best_num_features = max(ppv_scores, key=lambda x: x[1])[0]\n",
    "print(f'Numero ottimale di feature: {best_num_features}')\n",
    "\n",
    "# Usa il numero ottimale di feature per la classificazione finale\n",
    "X_optimal = X_ranked.iloc[:, :best_num_features]\n",
    "\n",
    "# Discretizza le feature ottimali\n",
    "X_discretized_opt = discretizer.fit_transform(X_optimal)\n",
    "\n",
    "# Divisione in train e test set\n",
    "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_discretized_opt, y, test_size=0.5, stratify=y)\n",
    "# Addestra il classificatore finale con le feature ottimali\n",
    "nb_classifier_opt = GaussianNB()\n",
    "nb_classifier_opt.fit(X_train_opt, y_train_opt)\n",
    "\n",
    "# Fai predizioni finali e valuta l'accuratezza\n",
    "y_pred_opt = nb_classifier_opt.predict(X_test_opt)\n",
    "final_accuracy = accuracy_score(y_test_opt, y_pred_opt)\n",
    "print(f'Final accuracy with {best_num_features} features: {final_accuracy}')\n",
    "\n",
    "# Bootstrap per valutare la stabilit√† dell'accuratezza\n",
    "n_iterations = 100\n",
    "bootstrap_accuracies = []\n",
    "\n",
    "for _ in range(n_iterations):\n",
    "    # Campionamento con rimpiazzo\n",
    "    indices = np.random.choice(len(X_train_opt), len(X_train_opt), replace=True)\n",
    "    X_train_bootstrap = X_train_opt[indices]\n",
    "    y_train_bootstrap = y_train_opt.iloc[indices]\n",
    "    \n",
    "    # Addestra il classificatore con il campione bootstrap\n",
    "    nb_classifier_bootstrap = GaussianNB()\n",
    "    nb_classifier_bootstrap.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "    \n",
    "    # Fai predizioni sul test set\n",
    "    y_pred_bootstrap = nb_classifier_bootstrap.predict(X_test_opt)\n",
    "    \n",
    "    # Calcola l'accuratezza\n",
    "    bootstrap_accuracy = accuracy_score(y_test_opt, y_pred_bootstrap)\n",
    "    bootstrap_accuracies.append(bootstrap_accuracy)\n",
    "\n",
    "# Calcola la media e l'intervallo di confidenza delle accuratezze bootstrap\n",
    "mean_accuracy = np.mean(bootstrap_accuracies)\n",
    "conf_interval = np.percentile(bootstrap_accuracies, [2.5, 97.5])\n",
    "\n",
    "print(f'Mean bootstrap accuracy: {mean_accuracy}')\n",
    "print(f'95% confidence interval for accuracy: {conf_interval}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
